{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: flask-cors in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.0.4)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flask) (1.8.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.5.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tonyz\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install flask flask-cors torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyz\\AppData\\Local\\Temp\\ipykernel_7940\\165285209.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('unet_model.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.1.216:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [01/Dec/2024 13:06:17] \"POST /api/calculate_vcdr HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from GlaucomaModel import UNet, vertical_cup_to_disc_ratio, refine_seg\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app, resources={r\"/*\": {\"origins\": \"*\"}})\n",
    "\n",
    "# Load the pre-trained model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_channels=3, n_classes=2).to(device)\n",
    "checkpoint = torch.load('unet_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Threshold for vCDR classification\n",
    "vCDR_threshold = 0.6\n",
    "\n",
    "# Preprocessing function for input images\n",
    "def preprocess(image):\n",
    "    # Ensure the image is in RGB format, regardless of original format\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    # Resize image to a fixed size while preserving aspect ratio and padding\n",
    "    size = (256, 256)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),  # Resize the shorter side to 256\n",
    "        transforms.CenterCrop(size),  # Crop the center to get a 256x256 image\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalization for pre-trained models\n",
    "    ])\n",
    "\n",
    "    return transform(image)\n",
    "\n",
    "@app.route('/api/calculate_vcdr', methods=['POST'])\n",
    "def calculate_vcdr():\n",
    "    if 'images' not in request.files:\n",
    "        return jsonify({\"error\": \"No files uploaded\"}), 400\n",
    "\n",
    "    files = request.files.getlist('images')\n",
    "    if not files:\n",
    "        return jsonify({\"error\": \"No files received\"}), 400\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Load and preprocess image\n",
    "            image = Image.open(file).convert('RGB')\n",
    "            input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "\n",
    "            # Forward pass through the model\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_tensor)\n",
    "\n",
    "            # Get segmentation predictions for OD and OC\n",
    "            pred_od = refine_seg((logits[:, 0, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:, 1, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "\n",
    "            # Compute vCDR\n",
    "            pred_vCDR = vertical_cup_to_disc_ratio(pred_od.cpu().numpy(), pred_oc.cpu().numpy())[0]\n",
    "\n",
    "            # Classify based on vCDR threshold\n",
    "            predicted_label = \"Glaucoma\" if pred_vCDR > vCDR_threshold else \"No Glaucoma\"\n",
    "\n",
    "            # Append the result\n",
    "            results.append({\n",
    "                \"file\": file.filename,\n",
    "                \"vCDR\": f\"{pred_vCDR:.2f}\",\n",
    "                \"prediction\": predicted_label\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file.filename}: {str(e)}\")\n",
    "            results.append({\"file\": file.filename, \"error\": str(e)})\n",
    "\n",
    "    return jsonify({\"results\": results}), 200\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
