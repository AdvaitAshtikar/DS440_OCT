{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets torch torchvision setuptools tensorflow kagglehub opencv-python numpy pandas scipy scikit-learn pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FwlA9iGSMBXq",
    "outputId": "cd8481cc-69a5-4800-9638-c5743c71386d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import kagglehub\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.ndimage import label\n",
    "from tensorflow import keras\n",
    "from keras._tf_keras.keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbDbgucCMHSj"
   },
   "outputs": [],
   "source": [
    "class GlaucomaDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', output_size=(256, 256)):\n",
    "        self.output_size = output_size\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.images = []\n",
    "        self.segs = []\n",
    "\n",
    "        for direct in self.root_dir:\n",
    "            self.image_filenames = []\n",
    "            for path in os.listdir(os.path.join(direct, \"Images_Square\")):\n",
    "                if not path.startswith('.'):\n",
    "                    self.image_filenames.append(path)\n",
    "\n",
    "            for k in range(len(self.image_filenames)):\n",
    "                try:\n",
    "                    print(f'Loading {split} image {k}/{len(self.image_filenames)}...', end='\\r')\n",
    "                    img_name = os.path.join(direct, \"Images_Square\", self.image_filenames[k])\n",
    "                    img = np.array(Image.open(img_name).convert('RGB'))\n",
    "                    img = transforms.functional.to_tensor(img)\n",
    "                    img = transforms.functional.resize(img, output_size, interpolation=Image.BILINEAR)\n",
    "                    self.images.append(img)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError loading image {self.image_filenames[k]}: {e}\")\n",
    "                    continue \n",
    "\n",
    "            if split != 'test':\n",
    "                for k in range(len(self.image_filenames)):\n",
    "                    try:\n",
    "                        print(f'Loading {split} segmentation {k}/{len(self.image_filenames)}...', end='\\r')\n",
    "                        seg_name = os.path.join(direct, \"Masks_Square\", self.image_filenames[k][:-3] + \"png\")\n",
    "                        mask = np.array(Image.open(seg_name, mode='r'))\n",
    "                        od = (mask == 1.).astype(np.float32)\n",
    "                        oc = (mask == 2.).astype(np.float32)\n",
    "                        od = torch.from_numpy(od[None, :, :])\n",
    "                        oc = torch.from_numpy(oc[None, :, :])\n",
    "                        od = transforms.functional.resize(od, output_size, interpolation=Image.NEAREST)\n",
    "                        oc = transforms.functional.resize(oc, output_size, interpolation=Image.NEAREST)\n",
    "                        self.segs.append(torch.cat([od, oc], dim=0))\n",
    "                    except Exception as e:\n",
    "                        print(f\"\\nError loading segmentation for {self.image_filenames[k]}: {e}\")\n",
    "                        continue \n",
    "\n",
    "            print(f'Successfully loaded {split} dataset.', ' ' * 50)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx]\n",
    "        if self.split == 'test':\n",
    "            return img\n",
    "        else:\n",
    "            seg = self.segs[idx]\n",
    "            return img, seg\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, image_dir, json_path, output_size=(256, 256)):\n",
    "        self.output_size = output_size\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        # Load images\n",
    "        self.image_filenames = []\n",
    "        for path in os.listdir(image_dir):\n",
    "            if not path.startswith('.'):\n",
    "                self.image_filenames.append(path)\n",
    "\n",
    "        # Load ground truth glaucoma labels from JSON file\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.ground_truth = json.load(f)\n",
    "\n",
    "        # Create a dictionary mapping from image filename to label\n",
    "        self.filename_to_label = {}\n",
    "        for item in self.ground_truth.values():\n",
    "            filename = item[\"ImgName\"]\n",
    "            label = item[\"Label\"]\n",
    "            self.filename_to_label[filename] = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_name = os.path.join(self.image_dir, self.image_filenames[idx])\n",
    "            img = np.array(Image.open(img_name).convert('RGB'))\n",
    "            img = transforms.functional.to_tensor(img)\n",
    "            img = transforms.functional.resize(img, self.output_size, interpolation=Image.BILINEAR)\n",
    "            file_id = self.image_filenames[idx]\n",
    "            has_glaucoma = self.filename_to_label.get(file_id, None)\n",
    "\n",
    "            if has_glaucoma is None:\n",
    "                raise KeyError(f\"Glaucoma label for '{file_id}' not found in ground_truth.\")\n",
    "\n",
    "            return img, int(has_glaucoma)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError loading file {self.image_filenames[idx]}: {e}\")\n",
    "            return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORs9x_eQMP6M"
   },
   "outputs": [],
   "source": [
    "EPS = 1e-7\n",
    "\n",
    "def compute_dice_coef(input, target):\n",
    "    batch_size = input.shape[0]\n",
    "    return sum([dice_coef_sample(input[k, :, :], target[k, :, :]) for k in range(batch_size)]) / batch_size\n",
    "\n",
    "def dice_coef_sample(input, target):\n",
    "    iflat = input.contiguous().view(-1)\n",
    "    tflat = target.contiguous().view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return (2. * intersection) / (iflat.sum() + tflat.sum())\n",
    "\n",
    "def vertical_diameter(binary_segmentation):\n",
    "    vertical_axis_diameter = np.sum(binary_segmentation, axis=1)\n",
    "    diameter = np.max(vertical_axis_diameter, axis=1)\n",
    "    return diameter\n",
    "\n",
    "def vertical_cup_to_disc_ratio(od, oc):\n",
    "    cup_diameter = vertical_diameter(oc)\n",
    "    disc_diameter = vertical_diameter(od)\n",
    "    return cup_diameter / (disc_diameter + EPS)\n",
    "\n",
    "def compute_vCDR_error(pred_od, pred_oc, gt_od, gt_oc):\n",
    "    pred_vCDR = vertical_cup_to_disc_ratio(pred_od, pred_oc)\n",
    "    gt_vCDR = vertical_cup_to_disc_ratio(gt_od, gt_oc)\n",
    "    vCDR_err = np.mean(np.abs(gt_vCDR - pred_vCDR))\n",
    "    return vCDR_err, pred_vCDR, gt_vCDR\n",
    "\n",
    "def refine_seg(pred):\n",
    "    np_pred = pred.numpy()\n",
    "    largest_ccs = []\n",
    "    for i in range(np_pred.shape[0]):\n",
    "        labeled, ncomponents = label(np_pred[i, :, :])\n",
    "        bincounts = np.bincount(labeled.flat)[1:]\n",
    "        largest_cc = labeled == np.argmax(bincounts) + 1 if len(bincounts) != 0 else labeled == 0\n",
    "        largest_ccs.append(torch.tensor(largest_cc, dtype=torch.float32))\n",
    "    return torch.stack(largest_ccs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JPKh7BDMR7Y"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=2):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.epoch = 0\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024)\n",
    "        self.down5 = Down(1024, 2048)\n",
    "        factor = 2\n",
    "        self.down6 = Down(2048, 4096 // factor)\n",
    "        self.up1 = Up(4096, 2048 // factor)\n",
    "        self.up2 = Up(2048, 1024 // factor)\n",
    "        self.up3 = Up(1024, 512 // factor)\n",
    "        self.up4 = Up(512, 256 // factor)\n",
    "        self.up5 = Up(256, 128 // factor)\n",
    "        self.up6 = Up(128, 64)\n",
    "        self.output_layer = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x6 = self.down5(x5)\n",
    "        x7 = self.down6(x6)\n",
    "        out = self.up1(x7, x6)\n",
    "        out = self.up2(out, x5)\n",
    "        out = self.up3(out, x4)\n",
    "        out = self.up4(out, x3)\n",
    "        out = self.up5(out, x2)\n",
    "        out = self.up6(out, x1)\n",
    "        return torch.sigmoid(self.output_layer(out))\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_channels, out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY, diffX = x2.size()[2] - x1.size()[2], x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        return self.conv(torch.cat([x2, x1], dim=1))\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tNdp0FYGRz_I",
    "outputId": "670815f8-3f78-4778-9bbe-141e4d1df501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded train dataset.                                                   \n",
      "Successfully loaded train dataset.                                                   \n",
      "Successfully loaded val dataset.                                                   \n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"arnavjain1/glaucoma-datasets\")\n",
    "train_dir = os.path.join(path, 'G1020')\n",
    "train_dir2 = os.path.join(path, 'ORIGA')\n",
    "train_dirs = [train_dir, train_dir2]\n",
    "val_dir = [os.path.join(path, 'REFUGE')]\n",
    "train_set = GlaucomaDataset(train_dirs, split='train')\n",
    "val_set = GlaucomaDataset(val_dir, split='val')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=8, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyz\\AppData\\Local\\Temp\\ipykernel_19992\\2048598210.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('unet_model.pth', map_location=device)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Model, Loss, Optimizer\n",
    "model = UNet(n_channels=3, n_classes=2).to(device)\n",
    "seg_loss = torch.nn.BCELoss(reduction='mean')\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "checkpoint = torch.load('unet_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# Training and Validation Loop\n",
    "nb_train_batches = len(train_loader)\n",
    "nb_val_batches = len(val_loader)\n",
    "nb_iter = 0\n",
    "best_val_auc = 0.\n",
    "iters = list(range(1, 10))\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDQ3bI40MTwc",
    "outputId": "1fd86b40-387e-41bd-a675-647157c17b3e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-666b9d55cf26>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('unet_model.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1                                                  \n",
      "Loss: 0.0050 (train), 0.0092 (val)\n",
      "Dice Score - OD segmentation: 0.8919 (train), 0.7881 (val)\n",
      "Dice Score - OC segmentation: 0.7498 (train), 0.8014 (val)\n",
      "vCDR error: 1.0212 (train), 0.1764 (val)\n",
      "Epoch 2                                                  \n",
      "Loss: 0.0043 (train), 0.0080 (val)\n",
      "Dice Score - OD segmentation: 0.8987 (train), 0.7908 (val)\n",
      "Dice Score - OC segmentation: 0.7553 (train), 0.8407 (val)\n",
      "vCDR error: 1.0104 (train), 0.1537 (val)\n",
      "Epoch 3                                                  \n",
      "Loss: 0.0037 (train), 0.0077 (val)\n",
      "Dice Score - OD segmentation: 0.9069 (train), 0.8185 (val)\n",
      "Dice Score - OC segmentation: 0.7617 (train), 0.8307 (val)\n",
      "vCDR error: 1.0112 (train), 0.1717 (val)\n",
      "Epoch 4                                                  \n",
      "Loss: 0.0034 (train), 0.0086 (val)\n",
      "Dice Score - OD segmentation: 0.9112 (train), 0.7827 (val)\n",
      "Dice Score - OC segmentation: 0.7712 (train), 0.8339 (val)\n",
      "vCDR error: 0.9739 (train), 0.1421 (val)\n",
      "Epoch 5                                                  \n",
      "Loss: 0.0032 (train), 0.0071 (val)\n",
      "Dice Score - OD segmentation: 0.9153 (train), 0.8379 (val)\n",
      "Dice Score - OC segmentation: 0.7752 (train), 0.8342 (val)\n",
      "vCDR error: 1.0253 (train), 0.1049 (val)\n",
      "Epoch 6                                                  \n",
      "Loss: 0.0030 (train), 0.0075 (val)\n",
      "Dice Score - OD segmentation: 0.9177 (train), 0.8165 (val)\n",
      "Dice Score - OC segmentation: 0.7792 (train), 0.8410 (val)\n",
      "vCDR error: 1.0159 (train), 0.1212 (val)\n",
      "Epoch 7                                                  \n",
      "Loss: 0.0029 (train), 0.0072 (val)\n",
      "Dice Score - OD segmentation: 0.9193 (train), 0.8318 (val)\n",
      "Dice Score - OC segmentation: 0.7841 (train), 0.8373 (val)\n",
      "vCDR error: 1.0040 (train), 0.2106 (val)\n",
      "Epoch 8                                                  \n",
      "Loss: 0.0028 (train), 0.0090 (val)\n",
      "Dice Score - OD segmentation: 0.9225 (train), 0.8023 (val)\n",
      "Dice Score - OC segmentation: 0.7835 (train), 0.8359 (val)\n",
      "vCDR error: 0.9961 (train), 0.1054 (val)\n",
      "Epoch 9                                                  \n",
      "Loss: 0.0028 (train), 0.0082 (val)\n",
      "Dice Score - OD segmentation: 0.9222 (train), 0.8141 (val)\n",
      "Dice Score - OC segmentation: 0.7873 (train), 0.8436 (val)\n",
      "vCDR error: 1.0792 (train), 0.1183 (val)\n",
      "Epoch 10                                                  \n",
      "Loss: 0.0031 (train), 0.0075 (val)\n",
      "Dice Score - OD segmentation: 0.9146 (train), 0.8299 (val)\n",
      "Dice Score - OC segmentation: 0.7793 (train), 0.8230 (val)\n",
      "vCDR error: 1.0039 (train), 0.1154 (val)\n",
      "Epoch 11                                                  \n",
      "Loss: 0.0027 (train), 0.0081 (val)\n",
      "Dice Score - OD segmentation: 0.9236 (train), 0.8259 (val)\n",
      "Dice Score - OC segmentation: 0.7885 (train), 0.8142 (val)\n",
      "vCDR error: 1.0122 (train), 0.2381 (val)\n",
      "Epoch 12                                                  \n",
      "Loss: 0.0028 (train), 0.0087 (val)\n",
      "Dice Score - OD segmentation: 0.9219 (train), 0.8176 (val)\n",
      "Dice Score - OC segmentation: 0.7864 (train), 0.8319 (val)\n",
      "vCDR error: 1.0029 (train), 0.1263 (val)\n",
      "Epoch 13                                                  \n",
      "Loss: 0.0023 (train), 0.0098 (val)\n",
      "Dice Score - OD segmentation: 0.9334 (train), 0.7965 (val)\n",
      "Dice Score - OC segmentation: 0.7992 (train), 0.8348 (val)\n",
      "vCDR error: 1.0335 (train), 0.1639 (val)\n",
      "Epoch 14                                                  \n",
      "Loss: 0.0023 (train), 0.0085 (val)\n",
      "Dice Score - OD segmentation: 0.9333 (train), 0.8324 (val)\n",
      "Dice Score - OC segmentation: 0.7976 (train), 0.8343 (val)\n",
      "vCDR error: 1.0265 (train), 0.0972 (val)\n",
      "Epoch 15                                                  \n",
      "Loss: 0.0021 (train), 0.0086 (val)\n",
      "Dice Score - OD segmentation: 0.9385 (train), 0.8301 (val)\n",
      "Dice Score - OC segmentation: 0.8055 (train), 0.8435 (val)\n",
      "vCDR error: 1.0157 (train), 0.1116 (val)\n",
      "Epoch 16                                                  \n",
      "Loss: 0.0020 (train), 0.0095 (val)\n",
      "Dice Score - OD segmentation: 0.9412 (train), 0.8167 (val)\n",
      "Dice Score - OC segmentation: 0.8062 (train), 0.8354 (val)\n",
      "vCDR error: 1.0236 (train), 0.1302 (val)\n",
      "Epoch 17                                                  \n",
      "Loss: 0.0019 (train), 0.0101 (val)\n",
      "Dice Score - OD segmentation: 0.9445 (train), 0.8167 (val)\n",
      "Dice Score - OC segmentation: 0.8097 (train), 0.8418 (val)\n",
      "vCDR error: 1.0258 (train), 0.1298 (val)\n",
      "Epoch 18                                                  \n",
      "Loss: 0.0018 (train), 0.0097 (val)\n",
      "Dice Score - OD segmentation: 0.9461 (train), 0.8179 (val)\n",
      "Dice Score - OC segmentation: 0.8131 (train), 0.8314 (val)\n",
      "vCDR error: 1.0285 (train), 0.1133 (val)\n",
      "Epoch 19                                                  \n",
      "Loss: 0.0018 (train), 0.0100 (val)\n",
      "Dice Score - OD segmentation: 0.9484 (train), 0.8234 (val)\n",
      "Dice Score - OC segmentation: 0.8128 (train), 0.8366 (val)\n",
      "vCDR error: 1.0229 (train), 0.1062 (val)\n",
      "Epoch 20                                                  \n",
      "Loss: 0.0017 (train), 0.0101 (val)\n",
      "Dice Score - OD segmentation: 0.9498 (train), 0.8259 (val)\n",
      "Dice Score - OC segmentation: 0.8150 (train), 0.8366 (val)\n",
      "vCDR error: 1.0218 (train), 0.1110 (val)\n",
      "Epoch 21                                                  \n",
      "Loss: 0.0017 (train), 0.0108 (val)\n",
      "Dice Score - OD segmentation: 0.9516 (train), 0.8230 (val)\n",
      "Dice Score - OC segmentation: 0.8164 (train), 0.8340 (val)\n",
      "vCDR error: 1.0079 (train), 0.1123 (val)\n",
      "Epoch 22                                                  \n",
      "Loss: 0.0016 (train), 0.0122 (val)\n",
      "Dice Score - OD segmentation: 0.9529 (train), 0.7952 (val)\n",
      "Dice Score - OC segmentation: 0.8176 (train), 0.8392 (val)\n",
      "vCDR error: 1.0343 (train), 0.1459 (val)\n",
      "Epoch 23                                                  \n",
      "Loss: 0.0016 (train), 0.0103 (val)\n",
      "Dice Score - OD segmentation: 0.9541 (train), 0.8254 (val)\n",
      "Dice Score - OC segmentation: 0.8189 (train), 0.8410 (val)\n",
      "vCDR error: 1.0055 (train), 0.1194 (val)\n",
      "Epoch 24                                                  \n",
      "Loss: 0.0015 (train), 0.0117 (val)\n",
      "Dice Score - OD segmentation: 0.9563 (train), 0.8192 (val)\n",
      "Dice Score - OC segmentation: 0.8207 (train), 0.8450 (val)\n",
      "vCDR error: 1.0272 (train), 0.1113 (val)\n",
      "Epoch 25                                                  \n",
      "Loss: 0.0015 (train), 0.0108 (val)\n",
      "Dice Score - OD segmentation: 0.9571 (train), 0.8304 (val)\n",
      "Dice Score - OC segmentation: 0.8213 (train), 0.8491 (val)\n",
      "vCDR error: 1.0008 (train), 0.1058 (val)\n"
     ]
    }
   ],
   "source": [
    "while model.epoch < num_epochs:\n",
    "    # Accumulators\n",
    "    train_vCDRs, val_vCDRs = [], []\n",
    "    train_loss, val_loss = 0., 0.\n",
    "    train_dsc_od, val_dsc_od = 0., 0.\n",
    "    train_dsc_oc, val_dsc_oc = 0., 0.\n",
    "    train_vCDR_error, val_vCDR_error = 0., 0.\n",
    "\n",
    "    model.train()\n",
    "    train_data = iter(train_loader)\n",
    "    for k in range(nb_train_batches):\n",
    "        imgs, seg_gts = next(train_data)\n",
    "        imgs, seg_gts = imgs.to(device), seg_gts.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        logits = model(imgs)\n",
    "        loss = seg_loss(logits, seg_gts)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() / nb_train_batches\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Compute segmentation metric\n",
    "            pred_od = refine_seg((logits[:, 0, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:, 1, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:, 0, :, :].type(torch.int8)\n",
    "            gt_oc = seg_gts[:, 1, :, :].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            train_dsc_od += dsc_od.item() / nb_train_batches\n",
    "            train_dsc_oc += dsc_oc.item() / nb_train_batches\n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            train_vCDRs += pred_vCDR.tolist()\n",
    "            train_vCDR_error += vCDR_error / nb_train_batches\n",
    "        nb_iter += 1\n",
    "        print('Epoch {}, iter {}/{}, loss {:.6f}'.format(model.epoch + 1, k + 1, nb_train_batches, loss.item()) + ' ' * 20,\n",
    "              end='\\r')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for k, (imgs, seg_gts) in enumerate(val_loader):\n",
    "            imgs, seg_gts = imgs.to(device), seg_gts.to(device)\n",
    "            logits = model(imgs)\n",
    "            val_loss += seg_loss(logits, seg_gts).item() / nb_val_batches\n",
    "            val_losses.append(val_loss)\n",
    "            print('Validation iter {}/{}'.format(k + 1, nb_val_batches) + ' ' * 50,\n",
    "                  end='\\r')\n",
    "            pred_od = refine_seg((logits[:, 0, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:, 1, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            gt_od = seg_gts[:, 0, :, :].type(torch.int8)\n",
    "            gt_oc = seg_gts[:, 1, :, :].type(torch.int8)\n",
    "            dsc_od = compute_dice_coef(pred_od, gt_od)\n",
    "            dsc_oc = compute_dice_coef(pred_oc, gt_oc)\n",
    "            val_dsc_od += dsc_od.item() / nb_val_batches\n",
    "            val_dsc_oc += dsc_oc.item() / nb_val_batches\n",
    "\n",
    "            vCDR_error, pred_vCDR, gt_vCDR = compute_vCDR_error(pred_od.cpu().numpy(), pred_oc.cpu().numpy(), gt_od.cpu().numpy(), gt_oc.cpu().numpy())\n",
    "            val_vCDRs += pred_vCDR.tolist()\n",
    "            val_vCDR_error += vCDR_error / nb_val_batches\n",
    "\n",
    "    print('Epoch {}'.format(model.epoch + 1) + ' ' * 50)\n",
    "    print('Loss: {:.4f} (train), {:.4f} (val)'.format(train_loss, val_loss))\n",
    "    print('Dice Score - OD segmentation: {:.4f} (train), {:.4f} (val)'.format(train_dsc_od, val_dsc_od))\n",
    "    print('Dice Score - OC segmentation: {:.4f} (train), {:.4f} (val)'.format(train_dsc_oc, val_dsc_oc))\n",
    "    print('vCDR error: {:.4f} (train), {:.4f} (val)'.format(train_vCDR_error, val_vCDR_error))\n",
    "    # End of epoch\n",
    "    model.epoch += 1\n",
    "\n",
    "save_path = '/content/unet_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "wXFXULDMMeNW",
    "outputId": "940cc135-fe72-47f4-9ca5-4f92bdcd417d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tonyz\\AppData\\Local\\Temp\\ipykernel_19992\\2306310973.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('unet_model.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for Glaucoma Classification: 89.50%\n",
      "True Positives (TP): 33\n",
      "True Negatives (TN): 325\n",
      "False Positives (FP): 35\n",
      "False Negatives (FN): 7\n",
      "Predictions have been saved to glaucoma_predictions.txt\n"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(path, 'REFUGE', 'train', 'Images')\n",
    "json_path = os.path.join(path, 'REFUGE', 'train', 'index.json')\n",
    "\n",
    "# Threshold for vCDR classification (e.g., images with vCDR > 0.6 are labeled as glaucoma)\n",
    "vCDR_threshold = 0.6\n",
    "test_set = TestDataset(test_dir, json_path)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "checkpoint = torch.load('unet_model.pth', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "tp, tn, fp, fn = 0, 0, 0, 0\n",
    "output_file_path = \"glaucoma_predictions.txt\" \n",
    "\n",
    "# Perform predictions and collect data\n",
    "with torch.no_grad():\n",
    "    predictions, ground_truth_labels = [], []\n",
    "    with open(output_file_path, \"w\") as f: \n",
    "        for (img, ground_truth_label), filename in zip(test_loader, test_set.image_filenames):\n",
    "            img = img.to(device)\n",
    "            logits = model(img)\n",
    "\n",
    "            # Get segmentation predictions for OD and OC\n",
    "            pred_od = refine_seg((logits[:, 0, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_oc = refine_seg((logits[:, 1, :, :] >= 0.5).type(torch.int8).cpu()).to(device)\n",
    "            pred_vCDR = vertical_cup_to_disc_ratio(pred_od.cpu().numpy(), pred_oc.cpu().numpy())[0]\n",
    "            predicted_label = int(pred_vCDR > vCDR_threshold)\n",
    "            ground_truth_label = int(ground_truth_label.item())\n",
    "            predictions.append(predicted_label)\n",
    "            ground_truth_labels.append(ground_truth_label)\n",
    "            f.write(\n",
    "                f\"Image: {filename}, vCDR: {pred_vCDR:.2f}, Prediction: {predicted_label}, Ground Truth: {ground_truth_label}\\n\"\n",
    "            )\n",
    "\n",
    "            # Update TP, TN, FP, FN counts\n",
    "            if predicted_label == 1 and ground_truth_label == 1:\n",
    "                tp += 1\n",
    "            elif predicted_label == 0 and ground_truth_label == 0:\n",
    "                tn += 1\n",
    "            elif predicted_label == 1 and ground_truth_label == 0:\n",
    "                fp += 1\n",
    "            elif predicted_label == 0 and ground_truth_label == 1:\n",
    "                fn += 1\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = np.mean([pred == gt for pred, gt in zip(predictions, ground_truth_labels)])\n",
    "\n",
    "with open(output_file_path, \"r+\") as f:\n",
    "    content = f.read()\n",
    "    f.seek(0, 0)\n",
    "    f.write(f\"Overall Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "    f.write(content)\n",
    "\n",
    "print(f\"Test Accuracy for Glaucoma Classification: {accuracy * 100:.2f}%\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"Predictions have been saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
